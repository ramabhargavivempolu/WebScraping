{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA SCIENCE AND PATTERN RECOGNITION**\n",
        "\n",
        "# PROJECT-1\n",
        "\n",
        "Rama Bhargavi Vempolu (1017440230)\n"
      ],
      "metadata": {
        "id": "isFoHZJxqsmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.\tAgriculture & Food Production â€“ Wikipedia Webpage\n",
        "\n",
        "This program analyzes the text content of a web page and identifies the top 10 most commonly used words in that content. It then displays a bar chart of the frequencies of those words.\n",
        "\n",
        "# Instructions to Install Required Libraries:\n",
        "\n",
        "This program requires the following libraries:\n",
        "\n",
        "* requests\n",
        "* re\n",
        "* nltk\n",
        "* pandas\n",
        "* matplotlib\n",
        "* beautifulsoup4\n",
        "\n",
        "To install these libraries, run the following command in your terminal:\n",
        "\n",
        "\n",
        "`pip install requests re nltk pandas matplotlib beautifulsoup4`\n",
        "\n",
        "Additionally, the program requires the following NLTK resources to be downloaded:\n",
        "\n",
        "* punkt\n",
        "* stopwords\n",
        "\n",
        "To download these resources, run the following commands in your Python environment:\n",
        "\n",
        "```\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "```\n",
        "\n",
        "# Description of Files:\n",
        "\n",
        "This program consists of a single Python file:\n",
        " \n",
        "* top_words.py: This file contains the code to retrieve the text content of a web page, tokenize it, remove stop words, count the frequency of each word, and display the top 10 most common words in a bar chart.\n",
        "\n",
        "# Explanation of the Code:\n",
        "\n",
        "After installing the required libraries, you can run the program and it will perform the following steps:\n",
        "\n",
        "* Send a GET request to the given Wikipedia URL using the requests library and retrieve the content.\n",
        "* Parse the HTML content using the BeautifulSoup library and extract the text content.\n",
        "* Clean the text data by converting it to lowercase and removing all non-alphabetic characters using regular expressions.\n",
        "* Tokenize the cleaned text using the word_tokenize function from the nltk library.\n",
        "* Remove the stop words from the tokenized words using the set of stopwords provided by the nltk library.\n",
        "* Find the frequency distribution of the remaining words using the FreqDist function from the nltk library.\n",
        "* Get the top 10 most common words and create a Pandas dataframe to display them.\n",
        "* Create a bar plot using the matplotlib library to visualize the frequency distribution of the top 10 most common words.\n",
        "\n",
        "The given code imports the required libraries and modules including requests, re, nltk, pandas, matplotlib and BeautifulSoup. It then downloads the content from the given Wikipedia URL using the requests library and extracts the text content using BeautifulSoup. The extracted text is then cleaned using regex, tokenized using the word_tokenize function from the nltk library, and stopwords are removed using the set of stopwords provided by the nltk library.\n",
        "\n",
        "Next, the frequency distribution of the remaining words is computed using the FreqDist function from the nltk library. The top 10 most common words and their frequency are then displayed using a Pandas dataframe. Finally, a bar plot is created using matplotlib to visualize the frequency distribution of the top 10 most common words.\n",
        "\n",
        "\n",
        "# 2. Beyond climate-smart agriculture (PDF file)\n",
        "\n",
        "\n",
        "This program analyzes a PDF file ('2048-7010-2-12.pdf') related to food safety and identifies the main area of improvement in food safety based on the frequency of certain keywords. The program also generates a bar plot of the frequency of all the words in the PDF file.\n",
        "\n",
        "# Instructions to Install Required Libraries:\n",
        "To run this program, the PyPDF2 library needs to be installed. The library can be installed using pip with the following command:\n",
        "\n",
        "`pip install PyPDF2`\n",
        "\n",
        "\n",
        "# Description of Files:\n",
        "\n",
        "* 2048-7010-2-12.pdf: This is the input PDF file that contains information related to food safety.\n",
        "\n",
        "# Explanation of the Code:\n",
        "\n",
        "The program begins by importing necessary libraries such as re, PyPDF2, collections, and matplotlib.pyplot. The 're' library is used for regular expression operations, PyPDF2 is used for reading the PDF file, collections and Counter are used for counting frequency of words, and matplotlib.pyplot is used for generating a bar plot.\n",
        "\n",
        "The program then reads the PDF file, extracts text from its first page, removes non-word characters using regular expressions, converts all the text to lowercase, and splits it into a list of words. It then uses the Counter object to count the frequency of each word.\n",
        "\n",
        "The program then defines four lists of keywords related to different aspects of food safety: cleanliness_keywords, training_keywords, temperature_keywords, and traceability_keywords. These lists are used to group keywords into topics related to food safety.\n",
        "\n",
        "The program then calculates the frequency of each topic by summing up the frequency of all the keywords in the respective topic. It then identifies the main area of improvement in food safety by selecting the topic with the highest frequency.\n",
        "\n",
        "Finally, the program generates a bar plot of the frequency of all the words in the PDF file using matplotlib.pyplot. The x-axis of the bar plot shows the topics, and the y-axis shows the frequency of each topic. The bar plot is titled \"Main areas of improvement in food safety\" and the x-tick labels are rotated by 90 degrees for better readability.\n",
        "\n",
        "Note: The input PDF file can be replaced with any other PDF file related to food safety to analyze and generate a bar plot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3. Global Food & Agriculture Statistics (csv file from Kaggle)\n",
        "\n",
        "# Instructions to Install Required Libraries:\n",
        "\n",
        "This program requires the following libraries to be installed: pandas, nltk, matplotlib, and multiprocessing.\n",
        "To install these libraries, you can use pip command in the command prompt:\n",
        "For pandas: `pip install pandas`\n",
        "For nltk: `pip install nltk`\n",
        "For matplotlib: `pip install matplotlib`\n",
        "For multiprocessing: `pip install multiprocessing`\n",
        "\n",
        "\n",
        "# Description of Files:\n",
        "\n",
        "* fao_data_crops_data.csv: This is a comma-separated values (CSV) file that contains data on crops from the Food and Agriculture Organization (FAO).\n",
        "* Top_words_country_names.py: This is a Python script that processes the data in fao_data_crops_data.csv and generates a bar chart of the top 10 words in country names.\n",
        "* README.md: This is the file that you are currently reading. It provides instructions for installing the required libraries and a brief description of the files in the program.\n",
        "\n",
        "\n",
        "# Explanation of the Code:\n",
        "\n",
        "* The code begins by importing the required libraries: pandas, nltk, matplotlib, and multiprocessing.\n",
        "\n",
        "* It then reads the data from the fao_data_crops_data.csv file using the pandas read_csv() function and stores it in the crops_data variable.\n",
        "\n",
        "* Next, the code downloads the required nltk data using the nltk.download() function.\n",
        "\n",
        "* The tokenize_text() function is defined using the nltk.word_tokenize() function to tokenize the text.\n",
        "\n",
        "* The multiprocessing.Pool() function is used to apply the tokenize_text() function to the country_or_area column in parallel and store the result in crops_data['country_or_area'].\n",
        "\n",
        "* The Counter() function is used to count the occurrence of each word in the crops_data['country_or_area'] column, and the top n words are selected using the most_common() function of Counter. Unwanted words are then removed using a for loop.\n",
        "\n",
        "* Finally, a pandas DataFrame is created from the top_words dictionary, and a bar chart of the top 10 words in country names is generated using the matplotlib library. The chart is then displayed using the plt.show() function."
      ],
      "metadata": {
        "id": "K1fl4ELdlfJj"
      }
    }
  ]
}